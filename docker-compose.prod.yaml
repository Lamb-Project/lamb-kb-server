services:
  backend:
    image: lamb-kb-server-backend:gpu
    build:
      context: ./backend
      args:
        - REQUIREMENTS_FILE=requirements-gpu.txt
    ports:
      - "9090:9090"
    env_file:
      - backend/.env
    environment:
      - FIRECRAWL_API_KEY=${FIRECRAWL_API_KEY}
      - FIRECRAWL_API_URL=${FIRECRAWL_API_URL}
      - PERPLEXITY_API_KEY=${PERPLEXITY_API_KEY}
    volumes:
      - kb-data:/home/nonroot/data
    networks:
      - app-network
    depends_on:
      - ollama

  ollama:
    build:
      context: ./ollama
      args:
        OLLAMA_EMBEDDING_MODEL: ${EMBEDDINGS_MODEL:-nomic-embed-text}
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_ORIGINS=*
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  kb-data:
    name: lamb-kb-data
  ollama-data:
    name: lamb-ollama-data
